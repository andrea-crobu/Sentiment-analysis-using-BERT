{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Dataset Preparation\n",
    "\n",
    "This notebook demonstrates the process of loading, cleaning, and converting the Twitter Entity Sentiment Analysis dataset from Kaggle into a format ready for machine learning using Hugging Face tools.\n",
    "\n",
    "## Steps:\n",
    "\n",
    "1. **Data Loading**\n",
    "   - The dataset is sourced from Kaggle under the name *twitter-entity-sentiment-analysis*.\n",
    "\n",
    "2. **Data Cleaning**\n",
    "   - Unrelevant entries (as specified in the dataset description on Kaggle) are removed to ensure that only pertinent data is processed.\n",
    "\n",
    "3. **Sentiment Conversion**\n",
    "   - The original sentiment labels are mapped to numerical values:\n",
    "     - **Positive** → 1\n",
    "     - **Negative** → 0\n",
    "     - **Neutral**  → 2\n",
    "\n",
    "4. **Text Tokenization**\n",
    "   - The text entries are tokenized using the `bert-base-uncased` tokenizer, preparing the text for subsequent modeling tasks.\n",
    "\n",
    "5. **Dataset Conversion**\n",
    "   - After preprocessing, the dataset is converted into a Hugging Face dataset format for compatibility.\n",
    "\n",
    "6. **Saving Locally**\n",
    "   - The final processed dataset is saved locally, ensuring easy access for future experiments or model training.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import kagglehub, os, random\n",
    "import pandas as pd\n",
    "\n",
    "from Pipeline.preprocessing.sentiment_analysis_Preprocessor import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model that will be used\n",
    "model_name = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jp797498e/twitter-entity-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['twitter_training.csv', 'twitter_validation.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the downloaded files\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       entity sentiment  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "                                                text  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_csv(path + '/twitter_training.csv', names=['id', 'entity', 'sentiment', 'text'])\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3364</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>I mentioned on Facebook that I was struggling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8312</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4371</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Negative</td>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4433</td>\n",
       "      <td>Google</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id     entity   sentiment  \\\n",
       "0  3364   Facebook  Irrelevant   \n",
       "1   352     Amazon     Neutral   \n",
       "2  8312  Microsoft    Negative   \n",
       "3  4371      CS-GO    Negative   \n",
       "4  4433     Google     Neutral   \n",
       "\n",
       "                                                text  \n",
       "0  I mentioned on Facebook that I was struggling ...  \n",
       "1  BBC News - Amazon boss Jeff Bezos rejects clai...  \n",
       "2  @Microsoft Why do I pay for WORD when it funct...  \n",
       "3  CSGO matchmaking is so full of closet hacking,...  \n",
       "4  Now the President is slapping Americans in the...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(path + '/twitter_validation.csv', names=['id', 'entity', 'sentiment', 'text'])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the documentation of the dataset, we can read that \n",
    "\n",
    "`There are three classes in this dataset: Positive, Negative and Neutral. We regard messages that are not relevant to the entity (i.e. Irrelevant) as Neutral.`\n",
    "\n",
    "The messages that are not relevant to an entity are marked as _Irrelevant_, but that doesn't tell if the message is _Positive_, _Negative_ or _Neutral_.\\\n",
    "For this reason, all the entries labeled as _Irrelevant_ will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: forums.com is the greatest spot to get free modz\n",
      "\n",
      "1: this baseball clip looks better than anything from the entire overwatch league\n",
      "\n",
      "2: Watch Dogs 2 is a copy of GTA, but the driving is lagged and poorly optimised, the characters are plain and boring (Wrench and Sitara are ok tho), disproportionate enemies' AI response, hacking mechanics and missions are repetitive (stealth, kill, hack) and shooting isn't worth\n",
      "\n",
      "3: Girls, what information???? Google conspiracies are your references when there are FOXY interviews that literally deny this....\n",
      "\n",
      "4: bruuuhhh oh wtf is wrong with me these good gay ass pc players\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print some examples or irrelevant tweets\n",
    "irrelevant_df = training_df[training_df['sentiment'] == 'Irrelevant']\n",
    "\n",
    "for index, example in enumerate(random.sample(irrelevant_df['text'].to_list(), 5)):\n",
    "    print(f'{index}: {example}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remothe the entries that have Irrelevant sentiment\n",
    "training_df = training_df[training_df['sentiment'] != 'Irrelevant']\n",
    "test_df = test_df[test_df['sentiment'] != 'Irrelevant'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to convert sentiment string to a digit, following the convention\n",
    "def convert_sentiment_to_digit(sentiment):\n",
    "    \"\"\"\n",
    "    Convert sentiment string to a digit.\n",
    "    \n",
    "    This function takes a string from the sentiment column and returns a digit.\n",
    "    The conversion is done as follows:\n",
    "        - 'Positive' -> 1\n",
    "        - 'Negative' -> 0\n",
    "        - 'Neutral' -> 2\n",
    "    \n",
    "    Args:\n",
    "        sentiment (str): The sentiment string to be converted.\n",
    "    \n",
    "    Returns:\n",
    "        int: The digit corresponding to the sentiment string.\n",
    "    \"\"\"\n",
    "    if sentiment == 'Positive':\n",
    "        return 1\n",
    "    elif sentiment == 'Negative':\n",
    "        return 0\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the desired preprocessing parameters\n",
    "input_preprocessing_params = {\n",
    "    'tokenizer': AutoTokenizer.from_pretrained(model_name),\n",
    "    'max_length': 128,\n",
    "    'truncation': True\n",
    "}\n",
    "\n",
    "output_preprocessing_params = {\n",
    "    'label_preprocess_fn': convert_sentiment_to_digit\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the Preprocessor class, from the Pipeline\n",
    "preprocessor = SentimentAnalysisPreprocessor(input_preprocessing_params, output_preprocessing_params)\n",
    "\n",
    "# preprocess the data\n",
    "preprocessed_training_data = preprocessor.preprocess_input_data(training_df['text'])\n",
    "preprocessed_test_data = preprocessor.preprocess_input_data(test_df['text'])\n",
    "\n",
    "preprocessed_training_labels = preprocessor.preprocess_output_data(training_df['sentiment'])\n",
    "preprocessed_test_labels = preprocessor.preprocess_output_data(test_df['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save locally the dataset, using the Hugging Face Dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first create a dictionay\n",
    "dataset = {\n",
    "    'train_set': {\n",
    "                    'input_ids': preprocessed_training_data,\n",
    "                    'labels': preprocessed_training_labels        \n",
    "                },\n",
    "\n",
    "    'test_set': {\n",
    "                    'input_ids': preprocessed_test_data,\n",
    "                    'labels': preprocessed_test_labels        \n",
    "                }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then convert each split into a Hugging Face Dataset\n",
    "train_dataset = Dataset.from_dict(dataset[\"train_set\"])\n",
    "test_dataset = Dataset.from_dict(dataset[\"test_set\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and finally pack it into a DatasetDict structure\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 61692\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 828\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save locally\n",
    "import pickle\n",
    "\n",
    "# Open a file in write-binary mode\n",
    "with open(\"data/dataset_sentiment_analysis.pkl\", \"wb\") as file:\n",
    "    # Serialize the list and save it to the file\n",
    "    pickle.dump(dataset, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
